{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "48fa5417-626b-43c9-a26a-a7b56f2571a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, Data Engineers!\nHi, My name is Vivek Purbey\nHi, My name is Vivek Purbey\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello, Data Engineers!\")\n",
    "f_name=\"Vivek\"\n",
    "l_name=\"Purbey\"\n",
    "print(\"Hi, My name is \"+ f_name+ \" \"+ l_name)\n",
    "#format a string\n",
    "print(f\"Hi, My name is {f_name} {l_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f5403fe7-be90-4b00-8bb6-8cce9bf376b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Enter your age and I will let you know you are eligibile for Voting or not:  25"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Congratulations, You are eligible for Voting.\n"
     ]
    }
   ],
   "source": [
    "age=int(input(\"Enter your age and I will let you know you are eligibile for Voting or not: \"))\n",
    "if age>=18:\n",
    "    print(\"Congratulations, You are eligible for Voting.\")\n",
    "else:\n",
    "    print(\"Sorry, You are not eligible for Voting!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e85f6a72-3796-4ba3-b984-a9b670c04bad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# %pip install pandas\n",
    "# %pip install openpyxl\n",
    "\n",
    "# dbutils.fs.mkdirs(\"/folder_name/\") #create a new folder in DBFS\n",
    "# dbutils.fs.rm('/FileStore/tables/employee_data-1.csv') #remove a file from DBFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "87f9c0b2-d102-45ff-b4c5-c5bc851fa248",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DoubleType\n",
    "\n",
    "# Sample data\n",
    "data = [\n",
    "    (101, \"Alice Johnson\", \"HR\", 55000, \"2020-03-15\", 88),\n",
    "    (102, \"Bob Smith\", \"Engineering\", 75000, \"2019-07-22\", 92),\n",
    "    (103, \"Charlie Lee\", None, 62000, \"2021-01-10\", 79),\n",
    "    (104, None, \"Engineering\", 81000, \"2018-11-05\", 95),\n",
    "    (105, \"Evan Kim\", \"Marketing\", None, \"2022-06-01\", 84)\n",
    "]\n",
    "\n",
    "# Schema\n",
    "schema = StructType([\n",
    "    StructField(\"EmployeeID\", IntegerType(), True),\n",
    "    StructField(\"Name\", StringType(), True),\n",
    "    StructField(\"Department\", StringType(), True),\n",
    "    StructField(\"Salary\", IntegerType(), True),\n",
    "    StructField(\"JoiningDate\", StringType(), True),\n",
    "    StructField(\"PerformanceScore\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "# Create Spark DataFrame\n",
    "df_spark = spark.createDataFrame(data, schema=schema)\n",
    "\n",
    "# Write as CSV (overwrite if already exists)\n",
    "df_spark.write.option(\"header\", True).mode(\"overwrite\").csv(\"/FileStore/employee_data\")\n",
    "\n",
    "df_read = spark.read.option(\"header\", True).csv(\"/FileStore/employee_data\")\n",
    "\n",
    "df = df_read.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a57b3fd-6150-4724-af27-8c9209eb8ca7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.databricks.v1+bamboolib_hint": "{\"pd.DataFrames\": [\"df\"], \"version\": \"0.0.1\"}",
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  EmployeeID           Name   Department Salary JoiningDate PerformanceScore\n0        102      Bob Smith  Engineering  75000  2019-07-22               92\n1        101  Alice Johnson           HR  55000  2020-03-15               88\n2        105       Evan Kim    Marketing   None  2022-06-01               84\n3        103    Charlie Lee         None  62000  2021-01-10               79\n4        104           None  Engineering  81000  2018-11-05               95\n  EmployeeID           Name   Department Salary JoiningDate PerformanceScore\n0        102      Bob Smith  Engineering  75000  2019-07-22               92\n1        101  Alice Johnson           HR  55000  2020-03-15               88\n2        105       Evan Kim    Marketing   None  2022-06-01               84\n3        103    Charlie Lee         None  62000  2021-01-10               79\n4        104           None  Engineering  81000  2018-11-05               95\n  EmployeeID           Name   Department Salary JoiningDate PerformanceScore\n0        102      Bob Smith  Engineering  75000  2019-07-22               92\n1        101  Alice Johnson           HR  55000  2020-03-15               88\n2        105       Evan Kim    Marketing   None  2022-06-01               84\n3        103    Charlie Lee         None  62000  2021-01-10               79\n4        104           None  Engineering  81000  2018-11-05               95\n  EmployeeID           Name   Department Salary JoiningDate PerformanceScore\n0        102      Bob Smith  Engineering  75000  2019-07-22               92\n1        101  Alice Johnson           HR  55000  2020-03-15               88\n2        105       Evan Kim    Marketing   None  2022-06-01               84\nEmployeeID                  102\nName                  Bob Smith\nDepartment          Engineering\nSalary                    75000\nJoiningDate          2019-07-22\nPerformanceScore             92\nName: 0, dtype: object\n  EmployeeID           Name   Department Salary JoiningDate PerformanceScore\n0        102      Bob Smith  Engineering  75000  2019-07-22               92\n1        101  Alice Johnson           HR  55000  2020-03-15               88\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 5 entries, 0 to 4\nData columns (total 6 columns):\n #   Column            Non-Null Count  Dtype \n---  ------            --------------  ----- \n 0   EmployeeID        5 non-null      object\n 1   Name              4 non-null      object\n 2   Department        4 non-null      object\n 3   Salary            4 non-null      object\n 4   JoiningDate       5 non-null      object\n 5   PerformanceScore  5 non-null      object\ndtypes: object(6)\nmemory usage: 368.0+ bytes\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EmployeeID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Department</th>\n",
       "      <th>Salary</th>\n",
       "      <th>JoiningDate</th>\n",
       "      <th>PerformanceScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>102</td>\n",
       "      <td>Bob Smith</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>75000</td>\n",
       "      <td>2019-07-22</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>EmployeeID</th>\n      <th>Name</th>\n      <th>Department</th>\n      <th>Salary</th>\n      <th>JoiningDate</th>\n      <th>PerformanceScore</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>5</td>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n      <td>5</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>5</td>\n      <td>4</td>\n      <td>3</td>\n      <td>4</td>\n      <td>5</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>102</td>\n      <td>Bob Smith</td>\n      <td>Engineering</td>\n      <td>75000</td>\n      <td>2019-07-22</td>\n      <td>92</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print(df) #return first 5 and last 5 records\n",
    "print(df.head()) #first 5\n",
    "print(df.tail()) #last 5\n",
    "print(df.head(3))\n",
    "print(df.loc[0]) #first record at 0th index in the form of table\n",
    "print(df.loc[[0, 1]])\n",
    "df.info()\n",
    "df.describe() #print the stastics of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce71c025-038a-4b30-931c-5d8f0ade7486",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Duration  Pulse  Maxpulse  Calories\n0        60    110       130       409\n1        60    117       145       479\n2        60    103       135       340\n3        45    109       175       282\n4        45    117       148       406\n5        60    102       127       300\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "  \"Duration\":{\n",
    "    \"0\":60,\n",
    "    \"1\":60,\n",
    "    \"2\":60,\n",
    "    \"3\":45,\n",
    "    \"4\":45,\n",
    "    \"5\":60\n",
    "  },\n",
    "  \"Pulse\":{\n",
    "    \"0\":110,\n",
    "    \"1\":117,\n",
    "    \"2\":103,\n",
    "    \"3\":109,\n",
    "    \"4\":117,\n",
    "    \"5\":102\n",
    "  },\n",
    "  \"Maxpulse\":{\n",
    "    \"0\":130,\n",
    "    \"1\":145,\n",
    "    \"2\":135,\n",
    "    \"3\":175,\n",
    "    \"4\":148,\n",
    "    \"5\":127\n",
    "  },\n",
    "  \"Calories\":{\n",
    "    \"0\":409,\n",
    "    \"1\":479,\n",
    "    \"2\":340,\n",
    "    \"3\":282,\n",
    "    \"4\":406,\n",
    "    \"5\":300\n",
    "  }\n",
    "}\n",
    "\n",
    "df_dict = pd.DataFrame(data)\n",
    "\n",
    "print(df_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "51562135-f19f-46e1-8728-103be2cc2024",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event</th>\n",
       "      <th>day</th>\n",
       "      <th>temperature</th>\n",
       "      <th>windspeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rain</td>\n",
       "      <td>1/1/2017</td>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sunny</td>\n",
       "      <td>1/2/2017</td>\n",
       "      <td>35</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Snow</td>\n",
       "      <td>1/3/2017</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Snow</td>\n",
       "      <td>1/4/2017</td>\n",
       "      <td>24</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rain</td>\n",
       "      <td>1/5/2017</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sunny</td>\n",
       "      <td>1/6/2017</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>event</th>\n      <th>day</th>\n      <th>temperature</th>\n      <th>windspeed</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Rain</td>\n      <td>1/1/2017</td>\n      <td>32</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Sunny</td>\n      <td>1/2/2017</td>\n      <td>35</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Snow</td>\n      <td>1/3/2017</td>\n      <td>28</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Snow</td>\n      <td>1/4/2017</td>\n      <td>24</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Rain</td>\n      <td>1/5/2017</td>\n      <td>32</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Sunny</td>\n      <td>1/6/2017</td>\n      <td>31</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "weather_data = {\n",
    "    'day': ['1/1/2017','1/2/2017','1/3/2017','1/4/2017','1/5/2017','1/6/2017'],\n",
    "    'temperature': [32,35,28,24,32,31],\n",
    "    'windspeed': [6,7,2,7,4,2],\n",
    "    'event': ['Rain', 'Sunny', 'Snow','Snow','Rain', 'Sunny']\n",
    "}\n",
    "df_weather=pd.DataFrame(weather_data)\n",
    "\n",
    "df_weather = spark.read.format('csv').options(header=True).load('dbfs:/FileStore/tables/weather_data.csv').toPandas()\n",
    "df_weather #.options(header='true') Sets options for reading the file : header='true', Telling Spark that the file has headers and tells Spark that the first row of the CSV file contains column names.\n",
    "\n",
    "df_weather.shape #rows, columns\n",
    "\n",
    "df_weather['event'] #df_weather.event\n",
    "type(df_weather['windspeed']) #type(df_weather.windspeed)\n",
    "df_weather[['windspeed', 'temperature', 'day']] #multiple columns select two brackets use: error-'Expected one value, found 0' if use only one bracket\n",
    "df_weather.temperature.max() #df_weather['temperature'].min/mean/count()\n",
    "#df_weather[df_weather['temperature']>28] : df_weather[df_weather.temperature > 28]\n",
    "'''df = pd.read_csv('data.csv', index_col=0) - remove the default indexing and set the first col as an index 1-second column...'''\n",
    "df_weather.set_index(['event'], inplace=True) #set_index returns a new dataframe\n",
    "df_weather.loc['Snow']\n",
    "df_weather.reset_index(inplace=True)\n",
    "df_weather\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8f74bf68-d2f8-42f1-9a81-b05aaaa17489",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        day temperature windspeed  event\n0  1/1/2017          32         6   Rain\n1  1/2/2017          35         7  Sunny\n2  1/3/2017          28         2   Snow\n3  1/4/2017          24         7   Snow\n4  1/5/2017          32         4   Rain\n5  1/6/2017          31         2  Sunny\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = spark.read.csv('dbfs:/FileStore/tables/weather_data.csv', header=True).toPandas()\n",
    "df\n",
    "\"\"\"\n",
    "read the data\n",
    "df=pd.read_csv(\"weather_data.csv\", skiprows=1/header=1, - skip the first record from the file header=None - assigns 0,1,2,3,..., names=['day', 'temperature', 'windspeed', 'event'] - use header=None and names=... if header is missing in csv files, nrows=3 - returns first 3 records from the file, na_values=[\"not available\", \"n.a\"] - replace all the \"not available\", \"n.a\" with NaN, \n",
    ")\n",
    "\n",
    "write the data\n",
    "df.to_csv('cleaned_weather_data.csv', index=False) - stored the cleaned data in this new file (cleaned_weather_data) without index   \n",
    "df.to_csv('new.csv', columns=['name', 'age']) - if we want to store few columns only, header=False - save the new file without header\n",
    "\"\"\"\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c21ec695-f7c0-45fd-af87-7325923dfff8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e354d918-8540-47d7-a4c2-8b41a7221062",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           _c0          _c1    _c2       _c3\n0         date      product  sales      task\n1   01-01-2023  electronics   1500      sold\n2   02-01-2023    groceries      0  returned\n3   03-01-2023     clothing   2000      sold\n4            X    groceries    300   damaged\n5   05-01-2023  electronics   -500  returned\n6      6012023     clothing   1800      sold\n7   07-01-2023  electronics   2200      sold\n8   01-08-2023            Y   2500      sold\n9   07-01-2023  electronics   2200      sold\n10  08-01-2023     clothing   1100  returned\n11  09-01-2023    groceries   2300   damaged\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_spark=spark.read.csv('dbfs:/FileStore/tables/sales_data.csv')\n",
    "df=df_spark.toPandas()\n",
    "\n",
    "\"\"\"cleaning empty cells: null/blank\"\"\"\n",
    "\n",
    "#df1=df.dropna() remove all the empty cells and return a new dataframe\n",
    "#print(df1)\n",
    "\n",
    "\"\"\"Syntax: DataFrameName.dropna(axis=0-rows/1-columns, how='any/all', inplace=True/False)\n",
    "- axis: axis takes int or string value for rows/columns. Input can be 0 or 1 for Integer and ‘index’ or ‘columns’ for String.\n",
    "- how: how takes string value of two kinds only (‘any’ or ‘all’). ‘any’ drops the row/column if ANY value is Null and ‘all’ drops only if ALL values are null.\n",
    "- inplace: It is a boolean which makes the changes in the data frame itself if True and inplace=False: do not change df itself — instead, return a new DataFrame.\n",
    "\"\"\"\n",
    "#df.dropna(axis=0, how='any', inplace=True)\n",
    "\"\"\"\n",
    "The fillna() method allows us to replace all the empty/NaN/None(null) cells with a value:\n",
    "\"\"\"\n",
    "#df1=df.fillna('X')\n",
    "df.fillna({\"_c0\": 'X', \"_c1\":'Y'}, inplace=True) #To only replace empty values for one column, specify the column name for the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ad9ae701-b4c4-4b3c-bb83-511f50b3499b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temperature</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>event</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1/1/2017</th>\n",
       "      <td>32.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>Rain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1/4/2017</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>Sunny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1/5/2017</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>None</td>\n",
       "      <td>Snow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1/6/2017</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1/7/2017</th>\n",
       "      <td>32.000000</td>\n",
       "      <td>None</td>\n",
       "      <td>Rain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1/8/2017</th>\n",
       "      <td>32.666667</td>\n",
       "      <td>None</td>\n",
       "      <td>Sunny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1/9/2017</th>\n",
       "      <td>33.333333</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1/10/2017</th>\n",
       "      <td>34.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>Cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1/11/2017</th>\n",
       "      <td>40.000000</td>\n",
       "      <td>12</td>\n",
       "      <td>Sunny</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>temperature</th>\n      <th>windspeed</th>\n      <th>event</th>\n    </tr>\n    <tr>\n      <th>day</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1/1/2017</th>\n      <td>32.000000</td>\n      <td>6</td>\n      <td>Rain</td>\n    </tr>\n    <tr>\n      <th>1/4/2017</th>\n      <td>30.000000</td>\n      <td>9</td>\n      <td>Sunny</td>\n    </tr>\n    <tr>\n      <th>1/5/2017</th>\n      <td>28.000000</td>\n      <td>None</td>\n      <td>Snow</td>\n    </tr>\n    <tr>\n      <th>1/6/2017</th>\n      <td>30.000000</td>\n      <td>7</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>1/7/2017</th>\n      <td>32.000000</td>\n      <td>None</td>\n      <td>Rain</td>\n    </tr>\n    <tr>\n      <th>1/8/2017</th>\n      <td>32.666667</td>\n      <td>None</td>\n      <td>Sunny</td>\n    </tr>\n    <tr>\n      <th>1/9/2017</th>\n      <td>33.333333</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>1/10/2017</th>\n      <td>34.000000</td>\n      <td>8</td>\n      <td>Cloudy</td>\n    </tr>\n    <tr>\n      <th>1/11/2017</th>\n      <td>40.000000</td>\n      <td>12</td>\n      <td>Sunny</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df=spark.read.format('csv').options(header=True).load('dbfs:/FileStore/tables/weather_data_cleaning.csv').toPandas()\n",
    "df.set_index('day', inplace=True)\n",
    "\n",
    "df1=df.fillna(0)\n",
    "df1\n",
    "\n",
    "df2=df.fillna({\n",
    "  'temperature': 0,\n",
    "  'windspeed': 0,\n",
    "  'event': 'No Event'\n",
    "})\n",
    "df2\n",
    "\n",
    "\"\"\"Use method to determine how to fill na values\"\"\"\n",
    "df3=df.fillna(method='ffill')\n",
    "df3\n",
    "\n",
    "df4=df.fillna(method='bfill')\n",
    "df4\n",
    "\n",
    "df['temperature'] = pd.to_numeric(df['temperature'], errors='coerce') #df['temperature'] = df['temperature'].fillna(0).astype(int)\n",
    "df5 = df.interpolate() #blank/NaN fill with the approx/interpollated/in-between values compared to above and below\n",
    "df5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8baa9272-a017-461c-ba1f-c8cdaef389de",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "replace method"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>student</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>rob</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>maya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>parthiv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>tom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>julian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>erica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>score</th>\n      <th>student</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>rob</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3</td>\n      <td>maya</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>parthiv</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>tom</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3</td>\n      <td>julian</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1</td>\n      <td>erica</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df=spark.read.format('csv').options(header=True).load('dbfs:/FileStore/tables/weather_data_replace_method.csv').toPandas()\n",
    "df1=df.replace('-99999', np.NaN) #df.replace('-99999', value=np.NaN), numpy has the attribute NaN\n",
    "df1\n",
    "df2=df.replace(['-99999', '-88888'], value=0)\n",
    "df2\n",
    "df3=df.replace(\n",
    "    {\n",
    "        'temperature': '-99999',\n",
    "        'windspeed': '-99999',\n",
    "        'event': '0'\n",
    "    }, np.NaN\n",
    ")\n",
    "df3\n",
    "df4=df.replace(\n",
    "    {\n",
    "        '-99999': np.NaN,\n",
    "        '0': 'Sunny'\n",
    "    }\n",
    ")\n",
    "df4\n",
    "\"\"\"\n",
    "regex is used to dictate the non-digit character and replace it with a some new value, entire dataset update\n",
    "\"\"\"\n",
    "df5=df.replace('[A-Za-z]', '', regex=True)\n",
    "df5=df.replace(\n",
    "    {\n",
    "        'temperature': '[A-Za-z]',\n",
    "        'windspeed': '[A-Za-z]'\n",
    "    }, '', regex=True\n",
    ")\n",
    "df6 = pd.DataFrame({\n",
    "    'score': ['exceptional','average', 'good', 'poor', 'average', 'exceptional'],\n",
    "    'student': ['rob', 'maya', 'parthiv', 'tom', 'julian', 'erica']\n",
    "})\n",
    "df6.replace(['exceptional', 'good', 'average', 'poor'], [1, 2, 3, 4], inplace=True)\n",
    "df6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b40ccb0f-22d3-4761-9e21-4ace9e09e894",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "GroupBy"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[12]: <pandas.core.groupby.generic.DataFrameGroupBy object at 0x7f20920efd30>"
     ]
    }
   ],
   "source": [
    "df=spark.read.format('csv').options(header=True).load('dbfs:/FileStore/tables/weather_by_cities.csv').toPandas()\n",
    "#if we perform calculations on string data type like average which will produce the incorrect result: str -> int\n",
    "df['temperature'] = pd.to_numeric(df['temperature'], errors='coerce')\n",
    "df['windspeed'] = pd.to_numeric(df['windspeed'], errors='coerce')\n",
    "df\n",
    "g=df.groupby('city')\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2be61ab2-a3a4-413e-9c9d-3a1fa56ecc6c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "city: mumbai\ndata:         day    city  temperature  windspeed  event\n4  1/1/2017  mumbai           90          5  Sunny\n5  1/2/2017  mumbai           85         12    Fog\n6  1/3/2017  mumbai           87         15    Fog\n7  1/4/2017  mumbai           92          5   Rain\ncity: new york\ndata:         day      city  temperature  windspeed  event\n0  1/1/2017  new york           32          6   Rain\n1  1/2/2017  new york           36          7  Sunny\n2  1/3/2017  new york           28         12   Snow\n3  1/4/2017  new york           33          7  Sunny\ncity: paris\ndata:          day   city  temperature  windspeed   event\n8   1/1/2017  paris           45         20   Sunny\n9   1/2/2017  paris           50         13  Cloudy\n10  1/3/2017  paris           54          8  Cloudy\n11  1/4/2017  paris           42         10  Cloudy\n"
     ]
    }
   ],
   "source": [
    "for city, data in g:\n",
    "    print(\"city:\",city)\n",
    "    print(\"data:\",data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "deec3a34-5341-4830-9045-943e4490c3eb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>city</th>\n",
       "      <th>temperature</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>event</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/1/2017</td>\n",
       "      <td>mumbai</td>\n",
       "      <td>90</td>\n",
       "      <td>5</td>\n",
       "      <td>Sunny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1/2/2017</td>\n",
       "      <td>mumbai</td>\n",
       "      <td>85</td>\n",
       "      <td>12</td>\n",
       "      <td>Fog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1/3/2017</td>\n",
       "      <td>mumbai</td>\n",
       "      <td>87</td>\n",
       "      <td>15</td>\n",
       "      <td>Fog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1/4/2017</td>\n",
       "      <td>mumbai</td>\n",
       "      <td>92</td>\n",
       "      <td>5</td>\n",
       "      <td>Rain</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>day</th>\n      <th>city</th>\n      <th>temperature</th>\n      <th>windspeed</th>\n      <th>event</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4</th>\n      <td>1/1/2017</td>\n      <td>mumbai</td>\n      <td>90</td>\n      <td>5</td>\n      <td>Sunny</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1/2/2017</td>\n      <td>mumbai</td>\n      <td>85</td>\n      <td>12</td>\n      <td>Fog</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1/3/2017</td>\n      <td>mumbai</td>\n      <td>87</td>\n      <td>15</td>\n      <td>Fog</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>1/4/2017</td>\n      <td>mumbai</td>\n      <td>92</td>\n      <td>5</td>\n      <td>Rain</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "g.get_group('mumbai')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "55984138-b4ec-4d92-a53c-d84072845175",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temperature</th>\n",
       "      <th>windspeed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mumbai</th>\n",
       "      <td>88.50</td>\n",
       "      <td>9.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new york</th>\n",
       "      <td>32.25</td>\n",
       "      <td>8.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paris</th>\n",
       "      <td>47.75</td>\n",
       "      <td>12.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>temperature</th>\n      <th>windspeed</th>\n    </tr>\n    <tr>\n      <th>city</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>mumbai</th>\n      <td>88.50</td>\n      <td>9.25</td>\n    </tr>\n    <tr>\n      <th>new york</th>\n      <td>32.25</td>\n      <td>8.00</td>\n    </tr>\n    <tr>\n      <th>paris</th>\n      <td>47.75</td>\n      <td>12.75</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"What was the maximum temperature in each of these 3 cities?\"\"\"\n",
    "g.max()\n",
    "\"\"\"What was the average windspeed in each of these 3 cities?\"\"\"\n",
    "g.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f164985b-28be-43d0-a79a-2d8a66f7dcc5",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Concat"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "      <th>city</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mumbai</td>\n",
       "      <td>32</td>\n",
       "      <td>80</td>\n",
       "      <td>new york</td>\n",
       "      <td>21</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>delhi</td>\n",
       "      <td>45</td>\n",
       "      <td>60</td>\n",
       "      <td>chicago</td>\n",
       "      <td>14</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>banglore</td>\n",
       "      <td>30</td>\n",
       "      <td>78</td>\n",
       "      <td>orlando</td>\n",
       "      <td>35</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>city</th>\n      <th>temperature</th>\n      <th>humidity</th>\n      <th>city</th>\n      <th>temperature</th>\n      <th>humidity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>mumbai</td>\n      <td>32</td>\n      <td>80</td>\n      <td>new york</td>\n      <td>21</td>\n      <td>68</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>delhi</td>\n      <td>45</td>\n      <td>60</td>\n      <td>chicago</td>\n      <td>14</td>\n      <td>65</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>banglore</td>\n      <td>30</td>\n      <td>78</td>\n      <td>orlando</td>\n      <td>35</td>\n      <td>75</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "india_weather = pd.DataFrame({\n",
    "    \"city\": [\"mumbai\",\"delhi\",\"banglore\"],\n",
    "    \"temperature\": [32,45,30],\n",
    "    \"humidity\": [80, 60, 78]\n",
    "})\n",
    "india_weather\n",
    "\n",
    "us_weather = pd.DataFrame({\n",
    "    'city': [\"new york\",\"chicago\",\"orlando\"],\n",
    "    'temperature': [21,14,35],\n",
    "    'humidity': [68, 65, 75]\n",
    "})\n",
    "us_weather\n",
    "\n",
    "df = pd.concat([india_weather, us_weather])\n",
    "df #second df index restart with 0\n",
    "\n",
    "df = pd.concat([india_weather, us_weather], ignore_index=True)\n",
    "df\n",
    "\n",
    "df = pd.concat([india_weather, us_weather], keys=[\"india\", \"us\"])\n",
    "df\n",
    "\n",
    "df.loc['india']\n",
    "\n",
    "df = pd.concat([india_weather, us_weather],axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8520bb86-2d7f-4723-8c15-32a18cec14e4",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Merge-Join"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>temperature_first</th>\n",
       "      <th>humidity_first</th>\n",
       "      <th>temperature_second</th>\n",
       "      <th>humidity_second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>new york</td>\n",
       "      <td>21.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chicago</td>\n",
       "      <td>14.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>orlando</td>\n",
       "      <td>35.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>baltimore</td>\n",
       "      <td>38.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>san diego</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.0</td>\n",
       "      <td>71.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>city</th>\n      <th>temperature_first</th>\n      <th>humidity_first</th>\n      <th>temperature_second</th>\n      <th>humidity_second</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>new york</td>\n      <td>21.0</td>\n      <td>65.0</td>\n      <td>14.0</td>\n      <td>68.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>chicago</td>\n      <td>14.0</td>\n      <td>68.0</td>\n      <td>21.0</td>\n      <td>65.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>orlando</td>\n      <td>35.0</td>\n      <td>71.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>baltimore</td>\n      <td>38.0</td>\n      <td>75.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>san diego</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>35.0</td>\n      <td>71.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df1 = pd.DataFrame({\n",
    "    \"city\": [\"new york\",\"chicago\",\"orlando\"],\n",
    "    \"temperature\": [21,14,35]\n",
    "})\n",
    "df2 = pd.DataFrame({\n",
    "    \"city\": [\"chicago\",\"new york\",\"orlando\"],\n",
    "    \"humidity\": [65,68,75],\n",
    "})\n",
    "\n",
    "df3=pd.merge(df1, df2, on='city') #by default: inner join = df3=pd.merge(df1, df2, on='city', how='inner')\n",
    "df3\n",
    "\n",
    "df1 = pd.DataFrame({\n",
    "    \"city\": [\"new york\",\"chicago\",\"orlando\", \"baltimore\"],\n",
    "    \"temperature\": [21,14,35, 38]\n",
    "})\n",
    "df2 = pd.DataFrame({\n",
    "    \"city\": [\"chicago\",\"new york\",\"san diego\"],\n",
    "    \"humidity\": [65,68,71]\n",
    "})\n",
    "\n",
    "df3=pd.merge(df1, df2, on='city', how='left')\n",
    "df3\n",
    "df3=pd.merge(df1, df2, on='city', how='right')\n",
    "df3\n",
    "df3=pd.merge(df1, df2, on='city', how='outer')\n",
    "df3\n",
    "'''by default indicator=false, indicator means: will tell us the result is coming from which table'''\n",
    "df4=pd.merge(df1, df2, on='city', how='outer', indicator=True)\n",
    "df4\n",
    "#suffixes, by default if both df columns are same it will create _x, _y ..., we can modify it\n",
    "df1 = pd.DataFrame({\n",
    "    \"city\": [\"new york\",\"chicago\",\"orlando\", \"baltimore\"],\n",
    "    \"temperature\": [21,14,35,38],\n",
    "    \"humidity\": [65,68,71, 75]\n",
    "})\n",
    "df2 = pd.DataFrame({\n",
    "    \"city\": [\"chicago\",\"new york\",\"san diego\"],\n",
    "    \"temperature\": [21,14,35],\n",
    "    \"humidity\": [65,68,71]\n",
    "})\n",
    "df3=pd.merge(df1, df2, on='city', how='outer')\n",
    "df3\n",
    "df3=pd.merge(df1, df2, on='city', how='outer', suffixes=('_first','_second'))\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c7bf7b5-b007-470b-a2d3-335b02da1dd4",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "pivot and pivot_table"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[18]: '\\nstack: is used to convert the columns of data into rows whereas unstack reverse rows into columns\\ndf = pd.read_excel(\"stocks.xlsx\",header=[0,1])-header tells it has two header level\\ndf.stack() - by default inner level of header convert, if we pass level then it will convert that header only\\ndf.stack(level=0)\\n'"
     ]
    }
   ],
   "source": [
    "df=spark.read.format('csv').options(header='True').load('dbfs:/FileStore/tables/weather_data.csv').toPandas()\n",
    "df1=df.pivot(index='day', columns='event') #index=what will by rows and columns=defines what will be the columns, values='temperature'-this will be my data in df\n",
    "df1\n",
    "\n",
    "'''pivot() is used to reshaping the data e.x: rows of data into columns whereas pivot_table() is used to summarize and aggregate data inside dataframe it means it is designed for aggregation like sum, mean etc.\n",
    "melt() is also used to transform and reshape the data\n",
    "'''\n",
    "\n",
    "df2=df.pivot_table(index='day', columns='temperature', aggfunc=np.sum) #df2=df.pivot_table(index='day', columns='temperature')\n",
    "df2\n",
    "'''\n",
    "stack: is used to convert the columns of data into rows whereas unstack reverse rows into columns\n",
    "df = pd.read_excel(\"stocks.xlsx\",header=[0,1])-header tells it has two header level\n",
    "df.stack() - by default inner level of header convert, if we pass level then it will convert that header only\n",
    "df.stack(level=0)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "489a437a-f9ae-4025-80c7-b5d79240366d",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "TimeSeries Analysis"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[19]: '\\ndf = pd.read_csv(\"aapl.csv\",parse_dates=[\"Date\"], index_col=\"Date\") - parse_dates changes the data type of date column from string(default) to datetime and index_col sets the date column as an index column\\ndf.head(2)\\nWhat is DatetimeIndex? Benefits of it:- Partial Date Index: Select Specific Months Data\\ndf[\\'2017-06-30\\'] - retrieves all the records where date is this\\ndf[\"2017-01\"] - all records where date is Jan 2017 and day is anything\\ndf[\\'2017-01-08\\':\\'2017-01-03\\'] - in between range retrieve\\n\\nResampling in Pandas refers to the process of changing the frequency of time series data. This is achieved primarily through the .resample() method, which is a powerful tool for time-based grouping and aggregation.\\n\\ndf[\\'Close\\'].resample(\\'M\\').mean().head() -M: Monthly, W: Weekly, Q:Quarterly\\n'"
     ]
    }
   ],
   "source": [
    "df=spark.read.format('csv').options(header=True).load('dbfs:/FileStore/tables/aapl.csv').toPandas()\n",
    "df\n",
    "'''\n",
    "df = pd.read_csv(\"aapl.csv\",parse_dates=[\"Date\"], index_col=\"Date\") - parse_dates changes the data type of date column from string(default) to datetime and index_col sets the date column as an index column\n",
    "df.head(2)\n",
    "What is DatetimeIndex? Benefits of it:- Partial Date Index: Select Specific Months Data\n",
    "df['2017-06-30'] - retrieves all the records where date is this\n",
    "df[\"2017-01\"] - all records where date is Jan 2017 and day is anything\n",
    "df['2017-01-08':'2017-01-03'] - in between range retrieve\n",
    "\n",
    "Resampling in Pandas refers to the process of changing the frequency of time series data. This is achieved primarily through the .resample() method, which is a powerful tool for time-based grouping and aggregation.\n",
    "\n",
    "df['Close'].resample('M').mean().head() -M: Monthly, W: Weekly, Q:Quarterly\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d94a6f8-bc01-4c30-8348-b93b9750bd3e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[20]: '\\ndf = pd.read_csv(\"aapl_no_dates.csv\") - the files doesn\\'t have the date column\\ndf.head()\\nrng = pd.date_range(start=\"6/1/2016\",end=\"6/30/2016\",freq=\\'B\\') -B: Business Days, excluding the holidays like sat, sun\\nrng\\ndf.set_index(rng, inplace=True)\\ndf.head()\\ndaily_index = pd.date_range(start=\"6/1/2016\",end=\"6/30/2016\",freq=\\'D\\') -D:Daily, M:Monthly\\ndf.asfreq(\\'D\\',method=\\'pad\\') --assigns if there is any gap like sat, sun with the previous values\\ndaily_index\\n'"
     ]
    }
   ],
   "source": [
    "'''\n",
    "df = pd.read_csv(\"aapl_no_dates.csv\") - the files doesn't have the date column\n",
    "df.head()\n",
    "rng = pd.date_range(start=\"6/1/2016\",end=\"6/30/2016\",freq='B') -B: Business Days, excluding the holidays like sat, sun\n",
    "rng\n",
    "df.set_index(rng, inplace=True)\n",
    "df.head()\n",
    "daily_index = pd.date_range(start=\"6/1/2016\",end=\"6/30/2016\",freq='D') -D:Daily, M:Monthly\n",
    "df.asfreq('D',method='pad') --assigns if there is any gap like sat, sun with the previous values\n",
    "daily_index\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "51d8d60f-3650-4c6d-86d1-8a8eb0388b5d",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "cleaning wrong format: to_datetime()"
    }
   },
   "outputs": [],
   "source": [
    "dates = ['2017-01-05', 'Jan 5, 2017', '01/05/2017', '2017.01.05', '2017/01/05','20170105']\n",
    "pd.to_datetime(dates)\n",
    "\n",
    "dt = ['2017-01-05 2:30:00 PM', 'Jan 5, 2017 14:30:00', '01/05/2016', '2017.01.05', '2017/01/05','20170105']\n",
    "pd.to_datetime(dt)\n",
    "\n",
    "pd.to_datetime('5-1-2016', dayfirst=True) #European style dates with day first\n",
    "\n",
    "'''custom date time format'''\n",
    "pd.to_datetime('2017$01$05', format='%Y$%m$%d')\n",
    "pd.to_datetime('2017#01#05', format='%Y#%m#%d')\n",
    "\n",
    "'''handling invalid dates'''\n",
    "pd.to_datetime(['2017-01-05', 'Jan 6, 2017', 'abc'], errors='ignore') #it just ignore the error which occur during the run time as well as the valid data and doesn't return any result\n",
    "pd.to_datetime(['2017-01-05', 'Jan 6, 2017', 'abc'], errors='coerce') #it just ignore the records which have error(wrong format) and replace it with NaT and the final result return in the same date format for all the records with NaT which have wrong record\n",
    "\n",
    "df.dropna(subset=['Date'], inplace = True) #removing the null values/Drop rows where date conversion failed (NaT)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Pandas Notebook",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}